{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALM 1 Ingest\n",
    "\n",
    "The present tutorial uses the ALM-1 data set to demonstrate how to build and use a DataJoint pipeline.\n",
    "\n",
    "The dataset is described here: https://crcns.org/data-sets/motor-cortex/alm-1/about-alm-1\n",
    "\n",
    "The data structure is described here: https://crcns.org/files/data/alm-1/crcns_alm-1_data_description.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install datajoint\n",
    "First, make sure that datajoint is installed and that you can import it.  The installation instructions are found at http://docs.datajoint.io/setup/Install-and-connect.html\n",
    "\n",
    "Then, import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import scio\n",
    "import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your database server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you will need to do is to obtain your database credentials.  Contact your database administrator for this information.  Set the credentials using the `dj.config` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dj.config['database.host'] = 'mesoscale-activity.datajoint.io'\n",
    "dj.config['database.user'] = 'dimitri'       # substitute your username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or connect to an existing database\n",
    "Next specify which `database` (aka _schema_) you will be working with.  Each data pipeline may comprise multiple schemas for different portions of the pipeline.  \n",
    "\n",
    "In in this tutorial we will work with only one schema called `tutorial_alm1`.  The following command will create the database if it does not already exist.  It also returns the object (called `schema`) that will be used to associate Python objects with tables in this database.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter DataJoint password: ········\n",
      "Connecting dimitri@mesoscale-activity.datajoint.io:3306\n"
     ]
    }
   ],
   "source": [
    "schema = dj.schema('tutorial_alm1', locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Animal and Session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as scio\n",
    "\n",
    "meta_data_path = 'data/ALM-1/meta_data'\n",
    "\n",
    "@schema\n",
    "class SessionDirectory(dj.Lookup):\n",
    "\n",
    "    definition = \"\"\"\n",
    "    session_file : varchar(255)    \n",
    "    \"\"\"\n",
    "    \n",
    "    contents = [[os.path.join(meta_data_path, f)]\n",
    "                for f in os.listdir(meta_data_path) if f.endswith('.mat')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@schema\n",
    "class Animal(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    animal :  int  # animal id \n",
    "    ---\n",
    "    species  : varchar(255)\n",
    "    date_of_birth : date\n",
    "    \"\"\"\n",
    "    \n",
    "    class GeneModification(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> Animal\n",
    "        gene_modification : varchar(30)\n",
    "        \"\"\"\n",
    "        \n",
    "    class Strain(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> Animal\n",
    "        strain  : varchar(30)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "@schema\n",
    "class Session(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Animal\n",
    "    session : tinyint \n",
    "    ---\n",
    "    session_date   :  date\n",
    "    session_suffix :  char(1) \n",
    "    -> SessionDirectory\n",
    "    UNIQUE INDEX(animal, session_date, session_suffix)\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def key_source(self):\n",
    "        return SessionDirectory()\n",
    "    \n",
    "    def _make_tuples(self, key):        \n",
    "        r = scio.loadmat(key['session_file'], \n",
    "                         struct_as_record=False, squeeze_me=True)['meta_data']\n",
    "        # extract animalID\n",
    "        if not isinstance(r.animalID, str):\n",
    "            r.animalID = r.animalID[0]   # handles errors in data\n",
    "        animal = int(r.animalID[3:])  \n",
    "        key['animal'] = animal\n",
    "        \n",
    "        # insert animal if first time\n",
    "        if not (Animal() & key):\n",
    "            tup = dict(\n",
    "                animal=animal,\n",
    "                species=r.species, \n",
    "                date_of_birth = \"{year}-{month}-{day}\".format(\n",
    "                    year=r.dateOfBirth[0:4], \n",
    "                    month=r.dateOfBirth[4:6], \n",
    "                    day=r.dateOfBirth[6:8]))\n",
    "            Animal().insert1(tup)\n",
    "            if isinstance(r.animalGeneModification, str):\n",
    "                r.animalGeneModification = [r.animalGeneModification]\n",
    "            Animal.GeneModification().insert(\n",
    "                dict(animal=animal, gene_modification=m) for m in r.animalGeneModification)\n",
    "            if isinstance(r.animalStrain, str):\n",
    "                r.animalStrain = [r.animalStrain]\n",
    "            Animal.Strain().insert(\n",
    "                dict(animal=animal, strain=m) for m in r.animalStrain)\n",
    "\n",
    "        tup = key\n",
    "        tup['session'] = len(Session() & dict(animal=animal))+1  \n",
    "        tup['session_date'] = \"{year}-{month}-{day}\".format(\n",
    "                year=r.dateOfExperiment[0:4], \n",
    "                month=r.dateOfExperiment[4:6], \n",
    "                day=r.dateOfExperiment[6:8])\n",
    "        tup['session_suffix'] = os.path.basename(key['session_file']).split('_')[3][8]\n",
    "        self.insert1(tup)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session().populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@schema\n",
    "class PhotoStim(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Session\n",
    "    ---\n",
    "    wavelength : decimal(4,1)\n",
    "    \"\"\"\n",
    "    \n",
    "    class Location(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> PhotoStim\n",
    "        photostim_loc  : tinyint \n",
    "        ---\n",
    "        area  : varchar(30)\n",
    "        photostim_x   :  decimal(4,2)    # mm\n",
    "        photostim_y   :  decimal(4,2)    # mm \n",
    "        \"\"\"\n",
    "        \n",
    "    class Method(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> PhotoStim\n",
    "        photostim_method : varchar(255)\n",
    "        \"\"\"\n",
    "        \n",
    "    def _make_tuples(self, key):\n",
    "        file = (Session() & key).fetch1['session_file']\n",
    "        print(file)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@schema\n",
    "class Recording(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> Session()\n",
    "    ---\n",
    "    recording_file : varchar(255)\n",
    "    \"\"\"\n",
    "    \n",
    "    def _make_tuples(self, key):\n",
    "        a = (Session() & key).fetch1()\n",
    "        if a['session_suffix']=='.':\n",
    "            a['session_suffix']=''\n",
    "        f = os.path.join(\n",
    "            'data', 'data_structure_ANM{animal:06d}',\n",
    "            'data_structure_ANM{animal:06d}_{short_date}{session_suffix}.mat').format(\n",
    "            **a, short_date=''.join(str(a['session_date']).split('-')))\n",
    "        assert os.path.isfile(f)\n",
    "        self.insert1(dict(key, recording_file=f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0066c7dc5d9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRecording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/datajoint-python/datajoint/autopopulate.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self, suppress_errors, reserve_jobs, order, limit, *restrictions)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Populating: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-2623062a9a8b>\u001b[0m in \u001b[0;36m_make_tuples\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;34m'data_structure_ANM{animal:06d}_{short_date}{session_suffix}.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             **a, short_date=''.join(str(a['session_date']).split('-')))\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecording_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Recording().populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Recording()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import units, trials, and spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@schema\n",
    "class Unit(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Recording\n",
    "    unit   :  smallint   # unit number on the array\n",
    "    ---\n",
    "    cell_type : varchar(30)\n",
    "    \"\"\"\n",
    "    \n",
    "    def _make_tuples(self, key):\n",
    "        f = (Recording() & key).fetch1['recording_file']\n",
    "        r = scio.loadmat(f, struct_as_record=False, squeeze_me=True)['obj'].eventSeriesHash\n",
    "        for name, value in zip(r.keyNames, r.value):\n",
    "            tup = key\n",
    "            tup['unit'] = int(name[4:])\n",
    "            tup['cell_type'] = value.cellType if isinstance(value.cellType, str) else ''\n",
    "            self.insert1(tup)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Unit().populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@schema\n",
    "class Trial(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Recording\n",
    "    trial  :  int \n",
    "    ---\n",
    "    start_time : double\n",
    "    pole_in_time =null:  double\n",
    "    pole_out_time =null : double\n",
    "    cue_time =null : double\n",
    "    good_trial  : tinyint   # change to bool\n",
    "    photostim_type =null :  tinyint\n",
    "    \"\"\"\n",
    "    \n",
    "    class Type(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> Trial\n",
    "        trial_type : varchar(12)\n",
    "        \"\"\"\n",
    "        \n",
    "    def _make_tuples(self, key):\n",
    "        print(key)\n",
    "        f = (Recording() & key).fetch1['recording_file']\n",
    "        obj = scio.loadmat(f, struct_as_record=False, squeeze_me=True)['obj']\n",
    "        names = ['pole_in_time', 'pole_out_time', 'cue_time', 'good_trial', 'photostim_type'];\n",
    "        ttype = Trial.Type()\n",
    "        trial_source = (dict(zip(names, n)) for n in zip(*obj.trialPropertiesHash.value))\n",
    "        for i, trial in enumerate(trial_source, start=1):\n",
    "            self.insert1(dict(key, trial=i, start_time=obj.trialStartTimes[i-1], **trial))\n",
    "            ttype.insert(dict(key, trial=i, trial_type=g) \n",
    "                         for g in obj.trialTypeStr[obj.trialTypeMat[:,i-1]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Trial().populate(reserve_jobs=True, suppress_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@schema\n",
    "class Spikes(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Unit\n",
    "    -> Trial\n",
    "    ---\n",
    "    spike_times : longblob    # spikes within trial\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def key_source(self):\n",
    "        return Recording() & Trial() & Unit()\n",
    "    \n",
    "    def _make_tuples(self, key):\n",
    "        print(key)\n",
    "        f = (Recording() & key).fetch1['recording_file']\n",
    "        obj = scio.loadmat(f, struct_as_record=False, squeeze_me=True)['obj']\n",
    "        for unit_name, value in zip(obj.eventSeriesHash.keyNames, obj.eventSeriesHash.value):\n",
    "            tup = dict(key, unit=int(unit_name[4:]))\n",
    "            self.insert(dict(tup, trial=trial, spike_times=value.eventTimes[value.eventTrials==trial]) \n",
    "                        for trial in set(value.eventTrials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Spikes().populate(suppress_errors=True, reserve_jobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dj.ERD(schema).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pick a dataset\n",
    "keys = list((Recording() & Spikes()).fetch.keys())\n",
    "key = keys[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot PSTHs of left (blue) vs right (red) trials\n",
    "print(key)\n",
    "good_trials = (Trial() & key & 'good_trial') - (Trial.Type() & 'trial_type in (\"LickEarly\", \"StimTrials\")')\n",
    "left_trials = good_trials & (Trial.Type() & 'trial_type in (\"HitL\")')\n",
    "right_trials = good_trials & (Trial.Type() & 'trial_type in (\"HitR\")')\n",
    "n_units = len(Unit() & key)\n",
    "print('Hits: left', len(left_trials), 'right', len(right_trials), 'Units: ', n_units)\n",
    "\n",
    "ncols = 4\n",
    "nrows = (n_units + ncols - 1)//ncols\n",
    "pylab.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "f, ax = plt.subplots(nrows, ncols)\n",
    "ax  = ax.flatten()\n",
    "bins = np.linspace(0,6,6)\n",
    "x = (bins[:-1]+bins[1:])/2\n",
    "for i, unit_key in enumerate((Unit() & key).fetch.keys()):\n",
    "    print(end='.')\n",
    "    left = (Trial()*Spikes() & unit_key & left_trials).fetch['start_time', 'spike_times']\n",
    "    if left[0].size:\n",
    "        left = np.concatenate([spikes-start for start, spikes in zip(*left)])\n",
    "        ax[i].hist(left, bins, color='blue', alpha=0.5)\n",
    "    right = (Trial()*Spikes() & unit_key & right_trials).fetch['start_time', 'spike_times']\n",
    "    if right[0].size:\n",
    "        right = np.concatenate([spikes-start for start, spikes in zip(*right)])\n",
    "        ax[i].hist(right, bins, color='red', alpha=0.5)\n",
    "    ax[i].set_title('Unit {unit}'.format(**unit_key))\n",
    "\n",
    "# clear unused axes\n",
    "for i in range(n_units,ncols*nrows):\n",
    "    ax[i].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
